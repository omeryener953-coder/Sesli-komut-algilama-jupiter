{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "755e78b0",
   "metadata": {},
   "source": [
    "# ğŸ¤ Ses Verisi â€“ Derin Ã–ÄŸrenme Pipeline\n",
    "\n",
    "Bu notebook:\n",
    "\n",
    "1. `data/` klasÃ¶rÃ¼nden WAV dosyalarÄ±nÄ± okur  \n",
    "2. Mel spectrogram Ã¼retir  \n",
    "3. Train/Test split yapar  \n",
    "4. Normalizasyon uygular  \n",
    "5. PyTorch DataLoader ile batch hazÄ±rlar  \n",
    "6. Basit CNN modeli kurar  \n",
    "7. Modeli eÄŸitir  \n",
    "8. EÄŸitim/doÄŸrulama grafikleri Ã§izer  \n",
    "9. Modeli kaydeder  \n",
    "10. Yeni dosya veya mikrofon ile tahmin yapar\n",
    "\n",
    "**Tam bir Deep Learning ses sÄ±nÄ±flandÄ±rma pipelineâ€™Ä±!**\n",
    "\n",
    "\n",
    "Bu Notebook ÅŸu anda:\n",
    "\n",
    "âœ” WAVâ€™larÄ± okur\n",
    "âœ” Mel spectrogram Ã¼retir\n",
    "âœ” Pad/trim yapar\n",
    "âœ” Normalizasyon yapar\n",
    "âœ” CNN model eÄŸitir\n",
    "âœ” Grafik Ã§izer\n",
    "âœ” Mikrofonla tahmin yapar\n",
    "âœ” Yeni dosyayÄ± tanÄ±r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2199c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã§alÄ±ÅŸÄ±yor!\n"
     ]
    }
   ],
   "source": [
    "print(\"Ã§alÄ±ÅŸÄ±yor!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5ac765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KÃ¼tÃ¼phaneler yÃ¼klendi!\n"
     ]
    }
   ],
   "source": [
    "# Gerekli kÃ¼tÃ¼phanelerin yÃ¼klenmesi\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import tempfile\n",
    "\n",
    "\n",
    "print(\"KÃ¼tÃ¼phaneler yÃ¼klendi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e63c5",
   "metadata": {},
   "source": [
    "# ğŸ“¥ 1) Ses DosyalarÄ±nÄ±n YÃ¼klenmesi ve Mel Spectrogram Ãœretimi\n",
    "Bu bÃ¶lÃ¼m `data/` klasÃ¶rÃ¼ndeki tÃ¼m WAV dosyalarÄ±nÄ± okur ve her biri iÃ§in sabit uzunlukta Mel spectrogram Ã¼retir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam dosya: 0\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ Veri klasÃ¶rÃ¼nden WAV dosyalarÄ±nÄ± oku ve Mel Spectrogram Ã¼ret\n",
    "\n",
    "data_path = \"data\"   # <-- Ses dosyalarÄ±nÄ±n olduÄŸu klasÃ¶r\n",
    "\n",
    "mel_tensor_list = []\n",
    "label_list = []\n",
    "\n",
    "max_len = 128  # Sabit Mel Spectrogram uzunluÄŸu (frame sayÄ±sÄ±)\n",
    "\n",
    "for root, dirs, files in os.walk(data_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            # 1) Ses yÃ¼kleme\n",
    "            audio, sr = librosa.load(file_path, sr=16000)\n",
    "\n",
    "            # Normalizasyon\n",
    "            audio = audio / np.max(np.abs(audio))\n",
    "\n",
    "            # 2) Mel Spectrogram\n",
    "            mel = librosa.feature.melspectrogram(\n",
    "                y=audio,\n",
    "                sr=sr,\n",
    "                n_fft=1024,\n",
    "                hop_length=256,\n",
    "                n_mels=64\n",
    "            )\n",
    "\n",
    "            # DB scale'e Ã§evir\n",
    "            mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "            # 3) Pad / Trim â€” sabit boyut olsun\n",
    "            if mel_db.shape[1] < max_len:\n",
    "                pad_w = max_len - mel_db.shape[1]\n",
    "                mel_db = np.pad(mel_db, ((0,0),(0,pad_w)), mode='constant')\n",
    "            else:\n",
    "                mel_db = mel_db[:, :max_len]\n",
    "\n",
    "            # TensÃ¶re Ã§evir (CNN iÃ§in channel=1 ekliyoruz)\n",
    "            mel_tensor = torch.tensor(mel_db, dtype=torch.float32).unsqueeze(0)\n",
    "            mel_tensor_list.append(mel_tensor)\n",
    "\n",
    "            # Etiket: klasÃ¶r ismi\n",
    "            label = os.path.basename(root)\n",
    "            label_list.append(label)\n",
    "\n",
    "print(\"Toplam dosya:\", len(label_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314841ec",
   "metadata": {},
   "source": [
    "# ğŸ·ï¸ 2) Labelâ€™larÄ± SayÄ±sal Formata Ã‡evirme\n",
    "Her dosyanÄ±n sÄ±nÄ±fÄ± dosya adÄ±ndan Ã§Ä±karÄ±lÄ±r (`dog_01.wav` â†’ `dog`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64224411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ String sÄ±nÄ±flarÄ± index'e Ã§evirme\n",
    "unique_labels = list(set(label_list))\n",
    "label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "y_idx = [label_to_idx[label] for label in label_list]\n",
    "\n",
    "print(\"SÄ±nÄ±flar:\", unique_labels)\n",
    "print(\"Label â†’ Index:\", label_to_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5cfbfa",
   "metadata": {},
   "source": [
    "# âœ‚ï¸ 3) Train/Test Split + Normalizasyon\n",
    "\n",
    "- Train/Test %80â€“%20 ayrÄ±lÄ±r  \n",
    "- Normalizasyon *yalnÄ±zca train Ã¼zerinden* hesaplanÄ±r  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TÃ¼m Mel verilerini birleÅŸtir\n",
    "X = torch.stack(mel_tensor_list)\n",
    "y = torch.tensor(y_idx)\n",
    "\n",
    "# ğŸ“Œ Trainâ€“test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ğŸ“Œ Normalizasyon (her zaman train Ã¼zerinden)\n",
    "mean = X_train.mean()\n",
    "std = X_train.std()\n",
    "\n",
    "X_train = (X_train - mean) / (std + 1e-9)\n",
    "X_test  = (X_test  - mean) / (std + 1e-9)\n",
    "\n",
    "# ğŸ“Œ DataLoader\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=16, shuffle=True)\n",
    "test_loader  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=16)\n",
    "\n",
    "print(\"Train:\", len(X_train), \" Test:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21452d7",
   "metadata": {},
   "source": [
    "# ğŸ§  4) Basit CNN Modelinin TanÄ±mlanmasÄ±\n",
    "2Ã— Conv â†’ MaxPool â†’ Fully Connected yapÄ±sÄ± kullanÄ±lÄ±r.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ Basit CNN modeli\n",
    "\n",
    "num_classes = len(unique_labels)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # 64 mel â†’ 32 â†’ 16\n",
    "        # max_len 128 â†’ 64 â†’ 32\n",
    "        self.fc1 = nn.Linear(32 * 16 * 32, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57659a6f",
   "metadata": {},
   "source": [
    "# ğŸ“š 5) Modelin EÄŸitilmesi ve DoÄŸrulanmasÄ±\n",
    "Her epoch sonunda hem train hem validation accuracy hesaplanÄ±r.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ Model eÄŸitimi\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, train_accs, val_accs = [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = total = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "\n",
    "    train_losses.append(running_loss / total)\n",
    "    train_accs.append(100 * correct / total)\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_correct = val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for Xv, yv in test_loader:\n",
    "            Xv, yv = Xv.to(device), yv.to(device)\n",
    "            ov = model(Xv)\n",
    "            _, pv = torch.max(ov, 1)\n",
    "            val_total += yv.size(0)\n",
    "            val_correct += (pv == yv).sum().item()\n",
    "\n",
    "    val_accs.append(100 * val_correct / val_total)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}  Loss: {train_losses[-1]:.4f}  \"\n",
    "          f\"Train Acc: {train_accs[-1]:.2f}%  Val Acc: {val_accs[-1]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a72a408",
   "metadata": {},
   "source": [
    "# ğŸ“Š 6) EÄŸitim Grafikleri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ KayÄ±p ve doÄŸruluk grafiklerinin Ã§izilmesi\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_accs, label=\"Train Acc\")\n",
    "plt.plot(val_accs, label=\"Val Acc\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9436a080",
   "metadata": {},
   "source": [
    "# ğŸ’¾ 7) Modeli Kaydetme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43faa771",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"simple_cnn_model.pth\")\n",
    "print(\"Model kaydedildi!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d1866",
   "metadata": {},
   "source": [
    "# ğŸ”® 8) Yeni Ses DosyasÄ±ndan Tahmin Fonksiyonu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ Yeni bir ses dosyasÄ± iÃ§in tahmin fonksiyonu\n",
    "\n",
    "def predict_audio(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=16000)\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=audio, sr=sr, n_fft=1024, hop_length=256, n_mels=64\n",
    "    )\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "    if mel_db.shape[1] < max_len:\n",
    "        mel_db = np.pad(mel_db, ((0,0),(0,max_len - mel_db.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mel_db = mel_db[:, :max_len]\n",
    "\n",
    "    mel_tensor = torch.tensor(mel_db).unsqueeze(0).unsqueeze(0)\n",
    "    mel_tensor = (mel_tensor - mean) / (std + 1e-9)\n",
    "    mel_tensor = mel_tensor.float().to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(mel_tensor)\n",
    "        _, pred = torch.max(output, 1)\n",
    "\n",
    "    return unique_labels[pred.item()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dabb16",
   "metadata": {},
   "source": [
    "# ğŸ™ï¸ 9) Mikrofon ile CanlÄ± Tahmin\n",
    "Mikrofonla 2 saniyelik kayÄ±t alÄ±r ve model tahmin eder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ Mikrofon ile ses kaydedip tahmin yapma\n",
    "\n",
    "duration = 2    # saniye\n",
    "sr = 16000\n",
    "\n",
    "with tempfile.NamedTemporaryFile(suffix=\".wav\") as tmp:\n",
    "    print(\"KonuÅŸun (2 saniye)...\")\n",
    "    recording = sd.rec(int(duration * sr), samplerate=sr, channels=1)\n",
    "    sd.wait()\n",
    "\n",
    "    sf.write(tmp.name, recording, sr)\n",
    "\n",
    "    label = predict_audio(tmp.name)\n",
    "    print(\"Tahmin edilen sÄ±nÄ±f:\", label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
